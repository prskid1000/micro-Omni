# Chapter 26: Training Workflow Overview

[Back to Index](00-INDEX.md)

---

## ğŸ¯ 5-Stage Training Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage A: Thinker Pretraining      â”‚
â”‚ Task: Next-token prediction        â”‚
â”‚ Data: Text corpus                  â”‚
â”‚ Time: ~8-12 hours (12GB GPU)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage B: Audio Encoder (ASR)      â”‚
â”‚ Task: Speech-to-text (CTC loss)   â”‚
â”‚ Data: Audio + transcriptions       â”‚
â”‚ Time: ~6-10 hours                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage C: Vision Encoder            â”‚
â”‚ Task: Image classification         â”‚
â”‚ Data: Images + captions            â”‚
â”‚ Time: ~4-8 hours                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage D: Talker + RVQ Codec        â”‚
â”‚ Task: Speech code prediction       â”‚
â”‚ Data: Audio for TTS                â”‚
â”‚ Time: ~10-15 hours                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage E: Multimodal SFT            â”‚
â”‚ Task: Joint multimodal tuning      â”‚
â”‚ Data: Mixed (text+image+audio)     â”‚
â”‚ Time: ~6-12 hours                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Training Summary

| Stage | Model | Task | Loss Function | Key Metric |
|-------|-------|------|---------------|------------|
| **A** | Thinker | Language Modeling | Cross-Entropy | Perplexity |
| **B** | Audio Encoder | ASR | CTC | WER |
| **C** | Vision Encoder | Image Understanding | Cross-Entropy | Accuracy |
| **D** | Talker + RVQ | Speech Generation | Cross-Entropy + MSE | Reconstruction |
| **E** | All (Joint) | Multimodal | Cross-Entropy | Mixed Accuracy |

## ğŸ¯ Training Strategy

### Modularity
- Each stage trains independently
- Debug issues in isolation
- Parallel development possible

### Efficiency
- Small datasets (<5GB per modality)
- Fits 12GB GPU with gradient accumulation
- Uses mixed precision (FP16)
- Gradient checkpointing for memory

### Progressive Learning
- Start with individual modalities
- End with joint understanding
- Specialized encoders preserved

## ğŸ’» Quick Start

```bash
# Stage A
python train_text.py --config configs/thinker_tiny.json

# Stage B
python train_audio_enc.py --config configs/audio_enc_tiny.json

# Stage C
python train_vision.py --config configs/vision_tiny.json

# Stage D
python train_talker.py --config configs/talker_tiny.json

# Stage E
python sft_omni.py --config configs/omni_sft_tiny.json
```

## ğŸ’¡ Key Takeaways

âœ… **5 independent stages** (modular design)  
âœ… **~40-60 hours total** training time (12GB GPU)  
âœ… **Small datasets** (<5GB each)  
âœ… **Progressive learning** (specialized â†’ joint)

---

[Back to Index](00-INDEX.md)

