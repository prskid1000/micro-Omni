# Chapter 43: Mathematical Foundations

[â† Previous: Performance Tuning](42-performance-tuning.md) | [Back to Index](00-INDEX.md) | [Next: Research Papers â†’](44-research-papers.md)

---

## ğŸ“ Core Mathematical Concepts

Mathematical foundations underlying Î¼Omni's architecture.

---

## ğŸ¯ Attention Mechanism

### Formula

```
Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V

Where:
- Q (queries): (seq_len, d_k)
- K (keys): (seq_len, d_k)
- V (values): (seq_len, d_v)
- d_k: key dimension (for scaling)
```

### Why It Works

**Dot product similarity:** `QK^T` measures how related each query is to each key

**Scaling:** `/ âˆšd_k` prevents large values in softmax (gradient stability)

**Soft selection:** `softmax()` converts to probabilities (0-1, sum to 1)

**Weighted sum:** Multiply by V to get attended values

---

## ğŸ”„ RoPE (Rotary Position Embedding)

### Formula

```
RoPE(x, m) = [
  [cos(mÎ¸â‚)  -sin(mÎ¸â‚)]   [xâ‚]
  [sin(mÎ¸â‚)   cos(mÎ¸â‚)] Ã— [xâ‚‚]
]

Where:
- m: position index
- Î¸áµ¢ = 10000^(-2i/d): frequency for dimension i
- Rotates embedding by position-dependent angle
```

### Properties

- **Relative positioning:** Naturally encodes relative distances
- **Extrapolation:** Works for sequences longer than training
- **Efficient:** No learned parameters

---

## ğŸ“Š Cross-Entropy Loss

### Formula

```
Loss = -Î£ yáµ¢ log(Å·áµ¢)

For classification:
Loss = -log(Å·_true_class)

Where:
- y: true distribution (one-hot)
- Å·: predicted probabilities (after softmax)
```

### Intuition

- Penalizes low probability on correct class
- Perfect prediction: loss = 0
- Completely wrong: loss = âˆ

---

## ğŸµ CTC Loss (for ASR)

### Formula

```
L_CTC = -log P(y|x)

Where P(y|x) sums over all valid alignments:
P(y|x) = Î£_{Ï€: B(Ï€)=y} Î _t P(Ï€â‚œ|x)

B(Ï€): CTC collapse function (removes blanks, repeated chars)
```

### Why CTC

- **Variable length:** Audio frames â‰  character count
- **No alignment needed:** Automatically finds best alignment
- **Efficient:** Dynamic programming for computation

---

## ğŸ”¢ Layer Normalization

### Formula

```
LayerNorm(x) = Î³ (x - Î¼) / âˆš(ÏƒÂ² + Îµ) + Î²

Where:
- Î¼ = mean(x): mean over features
- ÏƒÂ² = var(x): variance over features
- Î³, Î²: learnable scale and shift
- Îµ: small constant (1e-6) for stability
```

### RMSNorm (Î¼Omni uses this)

```
RMSNorm(x) = x / RMS(x) Ã— Î³

RMS(x) = âˆš(mean(xÂ²))

Simpler, faster, same effect!
```

---

## ğŸ² Softmax Function

### Formula

```
softmax(xáµ¢) = exp(xáµ¢) / Î£â±¼ exp(xâ±¼)

Properties:
- Output: probabilities (0-1, sum to 1)
- Differentiable: enables gradient descent
- Amplifies differences: large xáµ¢ â†’ high probability
```

### Temperature Scaling

```
softmax(x/T) where T > 0

T = 1: standard
T â†’ 0: argmax (deterministic)
T â†’ âˆ: uniform (random)
```

---

## ğŸ“ˆ Gradient Descent

### Formula

```
Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - Î· âˆ‡L(Î¸â‚œ)

Where:
- Î¸: model parameters
- Î·: learning rate
- âˆ‡L: gradient of loss
```

### Adam Optimizer (Î¼Omni uses)

```
mÌ‚â‚œ = Î²â‚mâ‚œ + (1-Î²â‚)gâ‚œ    // momentum
vÌ‚â‚œ = Î²â‚‚vâ‚œ + (1-Î²â‚‚)gâ‚œÂ²   // variance
Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - Î· mÌ‚â‚œ/âˆš(vÌ‚â‚œ + Îµ)

Benefits: Adaptive learning rates, momentum
```

---

## ğŸµ HiFi-GAN Vocoder Losses

### LSGAN (Least Squares GAN) Loss

**Discriminator Loss:**
```
L_D = Â½ E[(D(x_real) - 1)Â²] + Â½ E[D(x_fake)Â²]

Where:
- D(x_real): discriminator output for real audio (should be 1)
- D(x_fake): discriminator output for fake audio (should be 0)
- Uses MSE instead of cross-entropy (more stable gradients)
```

**Generator Adversarial Loss:**
```
L_G_adv = Â½ E[(D(x_fake) - 1)Â²]

Generator wants discriminator to output 1 for fake audio
```

### Feature Matching Loss

```
L_FM = E[Î£áµ¢ |fáµ¢(x_real) - fáµ¢(x_fake)|]

Where:
- fáµ¢: intermediate feature maps from discriminator layers
- L1 distance between real and fake features
- Stabilizes training by matching intermediate representations
```

### Mel Spectrogram Loss

```
L_mel = E[|mel_real - mel_fake|]

Where:
- mel_real: mel spectrogram of real audio
- mel_fake: mel spectrogram of generated audio
- L1 loss ensures frequency content matches
```

### Total Generator Loss

```
L_G = Î»_adv Ã— L_G_adv + Î»_fm Ã— L_FM + Î»_mel Ã— L_mel

Default weights (Î¼Omni):
- Î»_adv = 1.0   (adversarial)
- Î»_fm = 2.0    (feature matching)
- Î»_mel = 45.0  (mel spectrogram - highest weight)
```

### Why These Losses?

- **LSGAN:** More stable than standard GAN (smoother gradients)
- **Feature Matching:** Prevents mode collapse, improves quality
- **Mel Loss:** Ensures frequency content matches (critical for audio)

---

## ğŸ”Š HiFi-GAN Architecture

### Generator: Mel â†’ Audio

**Upsampling Formula:**
```
T_audio = T_mel Ã— hop_length

Example: 33 mel frames Ã— 256 hop = 8448 audio samples
```

**Multi-Receptive Field (MRF) Blocks:**
```
x_out = (xâ‚ + xâ‚‚ + ... + xâ‚™) / n

Where each xáµ¢ is from a residual block with different:
- Kernel sizes: [3, 7, 11]
- Dilation rates: [1, 3, 5]

Captures different temporal patterns simultaneously
```

**Output Activation:**
```
audio = Tanh(conv_post(x))

Tanh ensures output in [-1, 1] range (standard audio format)
```

### Multi-Period Discriminator (MPD)

**Period Reshaping:**
```
For period p:
x_reshaped = reshape(x, [B, 1, T//p, p])

Then applies 2D convolutions to capture periodic patterns
```

**Periods Used:** [2, 3, 5, 7, 11] - captures different temporal periodicities

### Multi-Scale Discriminator (MSD)

**Scale Downsampling:**
```
Scale 1: Original audio
Scale 2: AvgPool1d(4, 2) - 2Ã— downsampled
Scale 3: AvgPool1d(4, 2) again - 4Ã— downsampled

Captures patterns at different time scales
```

---

## ğŸ’¡ Key Insights

âœ… **Attention:** Weighted averaging based on similarity  
âœ… **RoPE:** Encodes position via rotation  
âœ… **Cross-entropy:** Measures prediction quality  
âœ… **CTC:** Handles variable-length alignment  
âœ… **Normalization:** Stabilizes training  
âœ… **Softmax:** Converts scores to probabilities  
âœ… **LSGAN:** Stable adversarial training with MSE loss  
âœ… **Feature Matching:** Prevents mode collapse in GANs  
âœ… **Mel Loss:** Ensures frequency-domain accuracy  
âœ… **MRF Blocks:** Captures multi-scale temporal patterns

---

[Continue to Chapter 44: Research Papers â†’](44-research-papers.md)

---
